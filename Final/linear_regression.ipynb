{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.svm as svm\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#digit intensity symmetry\n",
    "train = {}\n",
    "for digit in range(10):\n",
    "    train[digit] = []\n",
    "with open('features.train','r') as f:\n",
    "    for line in f:\n",
    "        line = [float(i) for i in line.split()]\n",
    "        train[line[0]].append(line[1:])\n",
    "for digit in range(10):\n",
    "    train[digit] = np.asarray(train[digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1005, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = {}\n",
    "for digit in range(10):\n",
    "    test[digit] = []\n",
    "with open('features.test','r') as f:\n",
    "    for line in f:\n",
    "        line = [float(i) for i in line.split()]\n",
    "        test[line[0]].append(line[1:])\n",
    "for digit in range(10):\n",
    "    test[digit] = np.asarray(test[digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(359, 2), (264, 2), (198, 2), (166, 2), (200, 2), (160, 2), (170, 2), (147, 2), (166, 2), (177, 2)]\n"
     ]
    }
   ],
   "source": [
    "print([test[i].shape for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_misclassified_point_idx(a,b):\n",
    "    idx = []\n",
    "    for i in range(len(a)):\n",
    "        if a[i] != b[i]:\n",
    "            idx.append(i)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def soft_margin_svm(train_data,train_class,test_data,test_class,C,kernel,degree=None):\n",
    "    if kernel is 'poly':\n",
    "        clf = svm.SVC(C = C, kernel = kernel, degree=degree, gamma=1,coef0 = 0)\n",
    "    else:\n",
    "        clf = svm.SVC(C = C, kernel = kernel,gamma=1)\n",
    "    clf.fit(train_data, train_class)\n",
    "    train_results = clf.predict(train_data)\n",
    "    idx = get_misclassified_point_idx(train_class,train_results)\n",
    "    e_in = len(idx)/float(len(train_class))\n",
    "    test_results = clf.predict(test_data)\n",
    "    idx = get_misclassified_point_idx(test_class,test_results)\n",
    "    e_out = len(idx)/float(len(test_class))\n",
    "    n_support_vecs = len(clf.support_)\n",
    "    \n",
    "    return e_in,e_out, n_support_vecs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_train_test_data_one_v_all(digit,train,test):\n",
    "    train_data = []\n",
    "    train_class = []\n",
    "    test_data = []\n",
    "    test_class = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        if i == digit:\n",
    "            class_id = -1\n",
    "        else:\n",
    "            class_id = 1\n",
    "\n",
    "        train_data.extend(train[i])\n",
    "        train_class.extend([class_id for j in train[i]])\n",
    "        test_data.extend(test[i])\n",
    "        test_class.extend([class_id for j in test[i]])\n",
    "        \n",
    "    return np.asarray(train_data),np.asarray(train_class), np.asarray(test_data), np.asarray(test_class)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_train_test_data_one_v_one(digit_1,digit_2,train,test):\n",
    "    train_data = []\n",
    "    train_class = []\n",
    "    test_data = []\n",
    "    test_class = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        if i == digit_1:\n",
    "            class_id = -1\n",
    "        elif i == digit_2:\n",
    "            class_id = 1\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        train_data.extend(train[i])\n",
    "        train_class.extend([class_id for j in train[i]])\n",
    "        test_data.extend(test[i])\n",
    "        test_class.extend([class_id for j in test[i]])\n",
    "        \n",
    "    return np.asarray(train_data),np.asarray(train_class), np.asarray(test_data), np.asarray(test_class)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_classification_error(X, w, y):\n",
    "    correct_idx = []\n",
    "    count = 0\n",
    "    for x in X:\n",
    "        if np.sign(w.dot(x)) == y[count]:\n",
    "            correct_idx.append(count)\n",
    "        count += 1\n",
    "    class_err = 1-len(correct_idx)/float(count) \n",
    "    return class_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_regression_weight_decay(X, y, l):\n",
    "    print(l)\n",
    "    X_plus = np.linalg.inv(X.transpose().dot(X) + l*np.eye(X.shape[1])).dot(X.transpose())\n",
    "    w = X_plus.dot(y)\n",
    "    return(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nonlinear_transform(X, k):\n",
    "    new_X = []\n",
    "    for x in X:\n",
    "        x1 = x[0]\n",
    "        x2 = x[1]\n",
    "        new_x = [1, x1, x2, x1*x2, x1**2, x2**2]\n",
    "        new_x = [new_x[i] for i in range(k+1)]\n",
    "        new_X.append(new_x)\n",
    "    return np.asarray(new_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def no_transform(X):\n",
    "    new_X = []\n",
    "    for x in X:\n",
    "        x1 = x[0]\n",
    "        x2 = x[1]\n",
    "        new_x = [1, x1, x2]\n",
    "        new_X.append(new_x)\n",
    "    new_X = np.asarray(new_X)\n",
    "#     print(new_X.shape)\n",
    "    return new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digit: 0\n",
      "E_in: 0.109312851461\n",
      "E_out: 0.11509715994\n",
      "Digit: 1\n",
      "E_in: 0.0152242490742\n",
      "E_out: 0.0224215246637\n",
      "Digit: 2\n",
      "E_in: 0.100260595254\n",
      "E_out: 0.0986547085202\n",
      "Digit: 3\n",
      "E_in: 0.0902482512687\n",
      "E_out: 0.0827105132038\n",
      "Digit: 4\n",
      "E_in: 0.0894253188863\n",
      "E_out: 0.0996512207275\n",
      "Digit: 5\n",
      "E_in: 0.0762584007681\n",
      "E_out: 0.079720976582\n",
      "Digit: 6\n",
      "E_in: 0.0910711836511\n",
      "E_out: 0.0847035376183\n",
      "Digit: 7\n",
      "E_in: 0.0884652311068\n",
      "E_out: 0.0732436472347\n",
      "Digit: 8\n",
      "E_in: 0.0743382252092\n",
      "E_out: 0.0827105132038\n",
      "Digit: 9\n",
      "E_in: 0.0883280757098\n",
      "E_out: 0.0881913303438\n"
     ]
    }
   ],
   "source": [
    "#x vs all experiments for each digit x\n",
    "l = 1\n",
    "e_ins = []\n",
    "e_outs = []\n",
    "support_vecs = []\n",
    "for digit in range(10):\n",
    "    print('Digit: '+str(digit))\n",
    "    X, y, test_X, test_y = create_train_test_data_one_v_all(digit,train,test)\n",
    "#     print(X.shape)\n",
    "    X = no_transform(X)\n",
    "#     print(X.shape)\n",
    "    w = linear_regression_weight_decay(X,y,l)\n",
    "    e_in = get_classification_error(X,w,y)\n",
    "#     print(test_X.shape)\n",
    "#     print(no_transform(test_X))\n",
    "    test_X = no_transform(test_X)\n",
    "#     print(test_X.shape)\n",
    "    e_out = get_classification_error(test_X,w,test_y)\n",
    "    \n",
    "    e_ins.append(e_in)\n",
    "    e_outs.append(e_out)\n",
    "\n",
    "    print('E_in: '+str(e_in))\n",
    "    print('E_out: '+str(e_out))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digit: 0\n",
      "E_in: 0.10231792621\n",
      "E_out: 0.106626806178\n",
      "Digit: 1\n",
      "E_in: 0.0123439857358\n",
      "E_out: 0.02192326856\n",
      "Digit: 2\n",
      "E_in: 0.100260595254\n",
      "E_out: 0.0986547085202\n",
      "Digit: 3\n",
      "E_in: 0.0902482512687\n",
      "E_out: 0.0827105132038\n",
      "Digit: 4\n",
      "E_in: 0.0894253188863\n",
      "E_out: 0.0996512207275\n",
      "Digit: 5\n",
      "E_in: 0.0762584007681\n",
      "E_out: 0.0792227204783\n",
      "Digit: 6\n",
      "E_in: 0.0910711836511\n",
      "E_out: 0.0847035376183\n",
      "Digit: 7\n",
      "E_in: 0.0884652311068\n",
      "E_out: 0.0732436472347\n",
      "Digit: 8\n",
      "E_in: 0.0743382252092\n",
      "E_out: 0.0827105132038\n",
      "Digit: 9\n",
      "E_in: 0.0883280757098\n",
      "E_out: 0.0881913303438\n"
     ]
    }
   ],
   "source": [
    "#x vs all experiments for each digit x, and nonlinear tform\n",
    "l = 1\n",
    "k = 5\n",
    "e_ins = []\n",
    "e_outs = []\n",
    "support_vecs = []\n",
    "for digit in range(10):\n",
    "    print('Digit: '+str(digit))\n",
    "    X, y, test_X, test_y = create_train_test_data_one_v_all(digit,train,test)\n",
    "    \n",
    "    Z = nonlinear_transform(X,k)\n",
    "    w = linear_regression_weight_decay(Z,y,l)\n",
    "    e_in = get_classification_error(Z,w,y)\n",
    "    \n",
    "    test_Z = nonlinear_transform(test_X,k)\n",
    "    e_out = get_classification_error(test_Z,w,test_y)\n",
    "    \n",
    "    e_ins.append(e_in)\n",
    "    e_outs.append(e_out)\n",
    "\n",
    "    print('E_in: '+str(e_in))\n",
    "    print('E_out: '+str(e_out))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digit: 0\n",
      "E_in: 0.109312851461\n",
      "E_out: 0.11509715994\n",
      "tform_E_in: 0.141544369771\n",
      "tform_E_out: 0.159940209268\n",
      "Digit: 1\n",
      "E_in: 0.0152242490742\n",
      "E_out: 0.0224215246637\n",
      "tform_E_in: 0.130709093403\n",
      "tform_E_out: 0.126557050324\n",
      "Digit: 2\n",
      "E_in: 0.100260595254\n",
      "E_out: 0.0986547085202\n",
      "tform_E_in: 0.100260595254\n",
      "tform_E_out: 0.0986547085202\n",
      "Digit: 3\n",
      "E_in: 0.0902482512687\n",
      "E_out: 0.0827105132038\n",
      "tform_E_in: 0.0902482512687\n",
      "tform_E_out: 0.0827105132038\n",
      "Digit: 4\n",
      "E_in: 0.0894253188863\n",
      "E_out: 0.0996512207275\n",
      "tform_E_in: 0.0894253188863\n",
      "tform_E_out: 0.0996512207275\n",
      "Digit: 5\n",
      "E_in: 0.0762584007681\n",
      "E_out: 0.079720976582\n",
      "tform_E_in: 0.0762584007681\n",
      "tform_E_out: 0.079720976582\n",
      "Digit: 6\n",
      "E_in: 0.0910711836511\n",
      "E_out: 0.0847035376183\n",
      "tform_E_in: 0.0910711836511\n",
      "tform_E_out: 0.0847035376183\n",
      "Digit: 7\n",
      "E_in: 0.0884652311068\n",
      "E_out: 0.0732436472347\n",
      "tform_E_in: 0.0884652311068\n",
      "tform_E_out: 0.0732436472347\n",
      "Digit: 8\n",
      "E_in: 0.0743382252092\n",
      "E_out: 0.0827105132038\n",
      "tform_E_in: 0.0743382252092\n",
      "tform_E_out: 0.0827105132038\n",
      "Digit: 9\n",
      "E_in: 0.0883280757098\n",
      "E_out: 0.0881913303438\n",
      "tform_E_in: 0.0883280757098\n",
      "tform_E_out: 0.0881913303438\n",
      "(True, False, False, False, False)\n"
     ]
    }
   ],
   "source": [
    "#compare with and without transform\n",
    "l = 1\n",
    "k = 5\n",
    "e_ins = []\n",
    "e_outs = []\n",
    "support_vecs = []\n",
    "a = True\n",
    "b = True\n",
    "c = True\n",
    "d = True\n",
    "e = False\n",
    "for digit in range(10):\n",
    "    print('Digit: '+str(digit))\n",
    "    X, y, test_X, test_y = create_train_test_data_one_v_all(digit,train,test)\n",
    "    X = no_transform(X)\n",
    "    w = linear_regression_weight_decay(X,y,l)\n",
    "    e_in = get_classification_error(X,w,y)\n",
    "    test_X = no_transform(test_X)\n",
    "    e_out = get_classification_error(test_X,w,test_y)\n",
    "    \n",
    "    e_ins.append(e_in)\n",
    "    e_outs.append(e_out)\n",
    "\n",
    "    print('E_in: '+str(e_in))\n",
    "    print('E_out: '+str(e_out))\n",
    "    \n",
    "    Z = nonlinear_transform(X,k)\n",
    "    w = linear_regression_weight_decay(Z,y,l)\n",
    "    tform_e_in = get_classification_error(Z,w,y)\n",
    "    \n",
    "    test_Z = nonlinear_transform(test_X,k)\n",
    "    tform_e_out = get_classification_error(test_Z,w,test_y)\n",
    "\n",
    "    print('tform_E_in: '+str(tform_e_in))\n",
    "    print('tform_E_out: '+str(tform_e_out))\n",
    "    \n",
    "    if tform_e_out < e_out:\n",
    "        if tform_e_in > e_in:\n",
    "            a = False    \n",
    "    if tform_e_out > 0.95*e_out:\n",
    "        b = False\n",
    "    if e_out != tform_e_out:\n",
    "        c = False\n",
    "    if e_out > 0.95*tform_e_out:\n",
    "        d = False\n",
    "    if digit == 5 and tform_e_out < e_out and tform_e_out > 0.95*e_out:\n",
    "        e = True\n",
    "\n",
    "print(a,b,c,d,e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda: 0.01\n",
      "0.01\n",
      "E_in: 0.0883280757098\n",
      "E_out: 0.0881913303438\n",
      "lambda: 1\n",
      "1\n",
      "E_in: 0.0883280757098\n",
      "E_out: 0.0881913303438\n",
      "lambda: 100\n",
      "100\n",
      "E_in: 0.0883280757098\n",
      "E_out: 0.0881913303438\n",
      "lambda: 0\n",
      "0\n",
      "E_in: 0.0883280757098\n",
      "E_out: 0.0881913303438\n",
      "b is true\n",
      "c is true\n"
     ]
    }
   ],
   "source": [
    "#1 vs 5 experiments\n",
    "k = 5\n",
    "digit_1 = 1\n",
    "digit_2 = 5\n",
    "e_ins = []\n",
    "e_outs = []\n",
    "\n",
    "train_data,train_class,test_data,test_class = create_train_test_data_one_v_one(digit_1,digit_2, train,test)\n",
    "for l in [.01,1,100,0]:\n",
    "    print('lambda: '+str(l))\n",
    "    Z = nonlinear_transform(X,k)\n",
    "    w = linear_regression_weight_decay(Z,y,l)\n",
    "    e_in = get_classification_error(Z,w,y)\n",
    "    \n",
    "    test_Z = nonlinear_transform(test_X,k)\n",
    "    e_out = get_classification_error(test_Z,w,test_y)\n",
    "       \n",
    "    print('E_in: '+str(e_in))\n",
    "    print('E_out: '+str(e_out))\n",
    "\n",
    "        \n",
    "    e_ins.append(e_in)\n",
    "    e_outs.append(e_out)\n",
    "\n",
    "\n",
    "if e_ins[0] == e_ins[1]:\n",
    "    print(\"b is true\")\n",
    "if e_outs[0] == e_outs[1]:\n",
    "    print(\"c is true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
